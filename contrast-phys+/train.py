# -*- coding: utf-8 -*-
import cv2
import matplotlib.pyplot as plt
import numpy as np
import os
import h5py
import torch
from PhysNetModel import PhysNet
from loss import ContrastLoss
from IrrelevantPowerRatio import IrrelevantPowerRatio

from utils_data import *
from utils_sig import *
from utils_paths import format_label_ratio, get_exp_root
from torch import optim
from torch.utils.data import DataLoader
from sacred import Experiment
from sacred.observers import FileStorageObserver

ex = Experiment('model_train', save_git_info=False)


if torch.cuda.is_available():
    device = torch.device('cuda')
    torch.backends.cudnn.enabled = True
    torch.backends.cudnn.benchmark = True
else:
    device = torch.device('cpu')

@ex.config
def my_config():
    # ======================================================================
    # å‚æ•°è®¾ç½®ï¼ˆè®­ç»ƒè¶…å‚æ•°ï¼‰
    # ======================================================================
    total_epoch = 30 # total number of epochs for training the model
    lr = 1e-5 # learning rate
    in_ch = 3 # TODO (README): number of input video channels, in_ch=3 for RGB videos, in_ch=1 for NIR videos.

    # ======================================================================
    # å‚æ•°è®¾ç½®ï¼ˆST-rPPG æ¨¡å—ï¼‰
    # ======================================================================
    fs = 30 # TODO (README): video frame rate, modify if your fps is not 30 fps.
    T = fs * 10 # temporal dimension of ST-rPPG block, default is 10 seconds.
    S = 2 # spatial dimenion of ST-rPPG block, default is 2x2.

    # ======================================================================
    # hyperparms å‚æ•°è®¾ç½®ï¼ˆrPPG æ—¶ç©ºé‡‡æ ·ï¼‰
    # ======================================================================
    delta_t = int(T/2) # time length of each rPPG sample
    K = 4 # the number of rPPG samples at each spatial position

    # ======================================================================
    # README ä¸­éœ€è¦æŒ‰æ•°æ®é›†è°ƒæ•´çš„é¡¹
    # ======================================================================
    label_ratio = 0 # TODO (README): labeled data ratio. Set 0 for fully unsupervised.

    # ======================================================================
    # å®éªŒ/è¿è¡Œè®¾ç½®
    # ======================================================================
    # æµ‹è¯•æ¨¡å¼ï¼šè®¾ç½®ä¸ºTrueæ—¶åªä½¿ç”¨å°‘é‡æ–‡ä»¶å¿«é€Ÿæµ‹è¯•
    test_mode = False

    train_exp_name = format_label_ratio(label_ratio)
    result_dir = get_exp_root(label_ratio)
    os.makedirs(result_dir, exist_ok=True)
    ex.observers.append(FileStorageObserver(result_dir))

@ex.automain
def my_main(_run, total_epoch, T, S, lr, result_dir, fs, delta_t, K, in_ch, label_ratio, test_mode):

    exp_dir = result_dir + '/%d'%(int(_run._id)) # store experiment recording to the path
    
    print("\n" + "="*60)
    print("è®­ç»ƒå®éªŒä¿¡æ¯")
    print("="*60)
    print("è®­ç»ƒå®éªŒID: {}".format(int(_run._id)))
    print("ç»“æœä¿å­˜ç›®å½•: {}".format(exp_dir))
    if test_mode:
        print("âš ï¸  æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨å°‘é‡æ•°æ®å¿«é€Ÿæµ‹è¯•")
    print("="*60 + "\n")

    # ======================================================================
    # æ•°æ®é›†åˆ’åˆ†ï¼ˆREADME: need to define your split function) including split ratio and test path
    # ======================================================================
    print("===å¼€å§‹è®­ç»ƒåˆå§‹åŒ–===")
    train_list, val_list, test_list = UBFC_LU_split(test_mode=test_mode) # TODO (README): define split for your dataset
    print("è®­ç»ƒé›†: {} ä¸ªæ–‡ä»¶, éªŒè¯é›†: {} ä¸ªæ–‡ä»¶, æµ‹è¯•é›†: {} ä¸ªæ–‡ä»¶".format(len(train_list), len(val_list), len(test_list)))
    np.save(exp_dir+'/train_list.npy', train_list)
    np.save(exp_dir+'/val_list.npy', val_list)
    np.save(exp_dir+'/test_list.npy', test_list)
    print("å·²ä¿å­˜è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†æ–‡ä»¶åˆ—è¡¨åˆ°: {}".format(exp_dir))

    # define the dataloader
    print("åˆ›å»ºæ•°æ®é›†å’ŒDataLoader...")
    train_dataset = H5Dataset(train_list, T, label_ratio) # please read the code about H5Dataset when preparing your dataset
    # åˆ›å»ºéªŒè¯é›†æ•°æ®é›†å’ŒDataLoader
    val_dataset = H5Dataset(val_list, T, label_ratio) if len(val_list) > 0 else None
    # ä¿®æ”¹ï¼šå¦‚æœè®­ç»ƒé›†æ–‡ä»¶æ•°å°‘äºbatch_sizeï¼Œè®¾ç½®drop_last=Falseä»¥é¿å…æ²¡æœ‰æ•°æ®å¯è®­ç»ƒ
    # æ³¨æ„ï¼šå¯¹æ¯”å­¦ä¹ éœ€è¦batch_size=2ï¼ˆä¸¤ä¸ªè§†é¢‘ï¼‰ï¼Œä½†å¦‚æœæ•°æ®é‡å°‘ï¼Œå¯ä»¥è®¾ç½®drop_last=False
    drop_last_setting = len(train_list) >= 2  # åªæœ‰å½“è®­ç»ƒé›†æ–‡ä»¶æ•°>=2æ—¶æ‰drop_last
    # GPUä¸Šå¯ä»¥å¯ç”¨å¤šè¿›ç¨‹å’Œpin_memoryåŠ é€Ÿï¼ŒCPUä¸Šä½¿ç”¨å•è¿›ç¨‹
    num_workers = 4 if torch.cuda.is_available() else 0
    pin_memory = True if torch.cuda.is_available() else False
    train_dataloader = DataLoader(train_dataset, batch_size=2, # two videos for contrastive learning
                            shuffle=True, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last_setting)
    # åˆ›å»ºéªŒè¯é›†DataLoaderï¼ˆå¦‚æœéªŒè¯é›†ä¸ä¸ºç©ºï¼‰
    val_dataloader = None
    if val_dataset is not None and len(val_list) >= 2:
        val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False, 
                                   num_workers=num_workers, pin_memory=pin_memory, drop_last=False)
    print("è®­ç»ƒé›†DataLoaderåˆ›å»ºå®Œæˆï¼Œæ•°æ®é›†é•¿åº¦: {}".format(len(train_dataset)))
    if val_dataset is not None:
        print("éªŒè¯é›†DataLoaderåˆ›å»ºå®Œæˆï¼Œæ•°æ®é›†é•¿åº¦: {}".format(len(val_dataset)))
    
    # define the model and loss
    print("åˆå§‹åŒ–æ¨¡å‹å’ŒæŸå¤±å‡½æ•°...")
    model = PhysNet(S, in_ch=in_ch).to(device).train()
    loss_func = ContrastLoss(delta_t, K, fs, high_pass=40, low_pass=250)

    # define irrelevant power ratio
    IPR = IrrelevantPowerRatio(Fs=fs, high_pass=40, low_pass=250)

    # define the optimizer
    opt = optim.AdamW(model.parameters(), lr=lr)
    print("å¼€å§‹è®­ç»ƒï¼Œå…± {} ä¸ªepoch".format(total_epoch))
    import sys
    sys.stdout.flush()
    
    # ç”¨äºè·Ÿè¸ªæœ€ä½³éªŒè¯losså’Œå¯¹åº”çš„epoch
    best_val_loss = float('inf')
    best_epoch = -1

    for e in range(total_epoch):
        print("\n=== Epoch {}/{} ===".format(e+1, total_epoch))
        sys.stdout.flush()
        # TODO: 60 means the video length of each video is 60s. If each video's length in your dataset is other value (e.g, 30s), you should use that value.
        # ä¿®æ”¹ï¼šæˆ‘ä»¬çš„è§†é¢‘é•¿åº¦çº¦51-67ç§’ï¼Œå¹³å‡çº¦60ç§’ï¼Œä½¿ç”¨60ç§’
        video_length_seconds = 60  # ä¿®æ”¹ï¼šé€‚é…æˆ‘ä»¬çš„è§†é¢‘é•¿åº¦ï¼ˆçº¦51-67ç§’ï¼Œå¹³å‡60ç§’ï¼‰
        num_iterations = np.round(video_length_seconds/(T/fs)).astype('int')
        print("  æ¯ä¸ªepochæœ‰ {} ä¸ªiteration".format(num_iterations))
        sys.stdout.flush()
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()  # ç¡®ä¿æ¨¡å‹å¤„äºè®­ç»ƒæ¨¡å¼
        epoch_train_losses = []
        for it in range(num_iterations):
            batch_count = 0
            for imgs, GT_sig, label_flag in train_dataloader: # dataloader randomly samples a video clip with length T
                batch_count += 1
                if batch_count == 1 and it == 0:
                    print("  å¼€å§‹å¤„ç†ç¬¬ä¸€ä¸ªbatch...")
                    sys.stdout.flush()
                imgs = imgs.to(device)
                GT_sig = GT_sig.to(device)
                label_flag = label_flag.to(device)
                
                # model forward propagation
                if batch_count == 1 and it == 0:
                    print("  æ•°æ®å·²è½¬ç§»åˆ°è®¾å¤‡ï¼Œå¼€å§‹æ¨¡å‹å‰å‘ä¼ æ’­...")
                    sys.stdout.flush()
                model_output = model(imgs) 
                rppg = model_output[:,-1] # get rppg
                if batch_count == 1 and it == 0:
                    print("  æ¨¡å‹å‰å‘ä¼ æ’­å®Œæˆï¼Œå¼€å§‹è®¡ç®—æŸå¤±...")
                    sys.stdout.flush()

                # define the loss functions
                loss, p_loss, n_loss, p_loss_gt, n_loss_gt = loss_func(model_output, GT_sig, label_flag)
                if batch_count == 1 and it == 0:
                    print("  æŸå¤±è®¡ç®—å®Œæˆï¼ŒTrain Loss: {:.6f}".format(loss.item()))
                    sys.stdout.flush()

                # optimize
                opt.zero_grad()
                loss.backward()
                opt.step()

                # evaluate irrelevant power ratio during training
                ipr = torch.mean(IPR(rppg.clone().detach()))

                # ç´¯ç§¯è®­ç»ƒlossç”¨äºè®¡ç®—epochå¹³å‡loss
                epoch_train_losses.append(loss.item())
                
                # save loss values and IPR (è®­ç»ƒé˜¶æ®µ)
                ex.log_scalar("train_loss", loss.item())
                ex.log_scalar("train_p_loss", p_loss.item())
                ex.log_scalar("train_n_loss", n_loss.item())
                ex.log_scalar("train_p_loss_gt", p_loss_gt.item())
                ex.log_scalar("train_n_loss_gt", n_loss_gt.item())
                ex.log_scalar("train_ipr", ipr.item())
                
                # æ¯10ä¸ªbatchè¾“å‡ºä¸€æ¬¡è¿›åº¦
                if batch_count % 10 == 0:
                    print("  Epoch {}, Iteration {}/{}, Batch {}, Train Loss: {:.6f}".format(e+1, it+1, num_iterations, batch_count, loss.item()))
                    sys.stdout.flush()
        
        # è®¡ç®—epochå¹³å‡è®­ç»ƒloss
        avg_train_loss = np.mean(epoch_train_losses) if epoch_train_losses else 0.0
        print("  Epoch {} å¹³å‡è®­ç»ƒLoss: {:.6f}".format(e+1, avg_train_loss))
        ex.log_scalar("epoch_train_loss", avg_train_loss, step=e+1)
        sys.stdout.flush()
        
        # éªŒè¯é˜¶æ®µ
        if val_dataloader is not None:
            model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
            epoch_val_losses = []
            epoch_val_p_losses = []
            epoch_val_n_losses = []
            epoch_val_p_gt_losses = []
            epoch_val_n_gt_losses = []
            epoch_val_iprs = []
            
            print("  å¼€å§‹éªŒè¯é›†è¯„ä¼°...")
            sys.stdout.flush()
            with torch.no_grad():  # éªŒè¯æ—¶ä¸éœ€è¦è®¡ç®—æ¢¯åº¦
                video_length_seconds = 60
                num_val_iterations = np.round(video_length_seconds/(T/fs)).astype('int')
                for it in range(num_val_iterations):
                    for imgs, GT_sig, label_flag in val_dataloader:
                        imgs = imgs.to(device)
                        GT_sig = GT_sig.to(device)
                        label_flag = label_flag.to(device)
                        
                        # model forward propagation
                        model_output = model(imgs)
                        rppg = model_output[:,-1]  # get rppg
                        
                        # è®¡ç®—æŸå¤±ï¼ˆä¸è¿›è¡Œåå‘ä¼ æ’­ï¼‰
                        loss, p_loss, n_loss, p_loss_gt, n_loss_gt = loss_func(model_output, GT_sig, label_flag)
                        
                        # è®¡ç®—IPR
                        ipr = torch.mean(IPR(rppg.clone().detach()))
                        
                        # ç´¯ç§¯éªŒè¯loss
                        epoch_val_losses.append(loss.item())
                        epoch_val_p_losses.append(p_loss.item())
                        epoch_val_n_losses.append(n_loss.item())
                        epoch_val_p_gt_losses.append(p_loss_gt.item())
                        epoch_val_n_gt_losses.append(n_loss_gt.item())
                        epoch_val_iprs.append(ipr.item())
            
            # è®¡ç®—epochå¹³å‡éªŒè¯loss
            avg_val_loss = np.mean(epoch_val_losses) if epoch_val_losses else 0.0
            avg_val_p_loss = np.mean(epoch_val_p_losses) if epoch_val_p_losses else 0.0
            avg_val_n_loss = np.mean(epoch_val_n_losses) if epoch_val_n_losses else 0.0
            avg_val_p_gt = np.mean(epoch_val_p_gt_losses) if epoch_val_p_gt_losses else 0.0
            avg_val_n_gt = np.mean(epoch_val_n_gt_losses) if epoch_val_n_gt_losses else 0.0
            avg_val_ipr = np.mean(epoch_val_iprs) if epoch_val_iprs else 0.0
            
            log_fmt = "  Epoch {} å¹³å‡éªŒè¯Loss: {:.6f} (P: {:.6f}, N: {:.6f}, IPR: {:.6f})"
            if label_ratio > 0 and (avg_val_p_gt != 0 or avg_val_n_gt != 0):
                log_fmt = "  Epoch {} å¹³å‡éªŒè¯Loss: {:.6f} (P: {:.6f}, N: {:.6f}, P_GT: {:.6f}, N_GT: {:.6f}, IPR: {:.6f})"
                print(log_fmt.format(e+1, avg_val_loss, avg_val_p_loss, avg_val_n_loss, avg_val_p_gt, avg_val_n_gt, avg_val_ipr))
            else:
                print(log_fmt.format(e+1, avg_val_loss, avg_val_p_loss, avg_val_n_loss, avg_val_ipr))
            sys.stdout.flush()
            
            # ä¿å­˜éªŒè¯æŒ‡æ ‡
            ex.log_scalar("val_loss", avg_val_loss, step=e+1)
            ex.log_scalar("val_p_loss", avg_val_p_loss, step=e+1)
            ex.log_scalar("val_n_loss", avg_val_n_loss, step=e+1)
            ex.log_scalar("val_p_loss_gt", avg_val_p_gt, step=e+1)
            ex.log_scalar("val_n_loss_gt", avg_val_n_gt, step=e+1)
            ex.log_scalar("val_ipr", avg_val_ipr, step=e+1)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹ï¼ˆéªŒè¯lossæ›´ä½ï¼‰
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                best_epoch = e
                print("  âœ… å‘ç°æ›´å¥½çš„æ¨¡å‹ï¼éªŒè¯Loss: {:.6f} (Epoch {})".format(best_val_loss, best_epoch+1))
                sys.stdout.flush()
        else:
            print("  è·³è¿‡éªŒè¯ï¼ˆéªŒè¯é›†ä¸ºç©ºæˆ–æ–‡ä»¶æ•°ä¸è¶³ï¼‰")
            sys.stdout.flush()

        # save model checkpoints
        print("ä¿å­˜Epoch {}çš„æ¨¡å‹æ£€æŸ¥ç‚¹...".format(e+1))
        sys.stdout.flush()
        checkpoint_path = exp_dir+'/epoch%d.pt'%e
        torch.save(model.state_dict(), checkpoint_path)
        print("Epoch {} å®Œæˆï¼Œæ¨¡å‹æƒé‡å·²ä¿å­˜åˆ°: {}".format(e+1, checkpoint_path))
        sys.stdout.flush()
        
        # å¦‚æœæ˜¯å½“å‰æœ€ä½³æ¨¡å‹ï¼Œé¢å¤–ä¿å­˜ä¸€ä»½best_model.pt
        if val_dataloader is not None and e == best_epoch:
            best_model_path = exp_dir+'/best_model.pt'
            torch.save(model.state_dict(), best_model_path)
            print("  ğŸ’¾ å·²ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°: {} (éªŒè¯Loss: {:.6f})".format(best_model_path, best_val_loss))
            sys.stdout.flush()
    
    # è®­ç»ƒå®Œæˆåçš„æ€»ç»“ä¿¡æ¯
    print("\n" + "="*60)
    print("è®­ç»ƒå®Œæˆï¼")
    print("="*60)
    print("è®­ç»ƒå®éªŒID: {}".format(int(_run._id)))
    print("ç»“æœä¿å­˜ç›®å½•: {}".format(exp_dir))
    print("\nä¿å­˜çš„æ–‡ä»¶:")
    print("  - train_list.npy: è®­ç»ƒé›†æ–‡ä»¶åˆ—è¡¨")
    print("  - val_list.npy: éªŒè¯é›†æ–‡ä»¶åˆ—è¡¨")
    print("  - test_list.npy: æµ‹è¯•é›†æ–‡ä»¶åˆ—è¡¨")
    print("  - epoch0.pt ~ epoch{}.pt: æ¯ä¸ªepochçš„æ¨¡å‹æƒé‡".format(total_epoch-1))
    if val_dataloader is not None and best_epoch >= 0:
        print("  - best_model.pt: æœ€ä½³æ¨¡å‹ï¼ˆEpoch {}, éªŒè¯Loss: {:.6f}ï¼‰".format(best_epoch+1, best_val_loss))
    print("  - config.json: è®­ç»ƒé…ç½®ï¼ˆSacredè‡ªåŠ¨ä¿å­˜ï¼‰")
    print("  - run.json: è¿è¡Œä¿¡æ¯ï¼ˆSacredè‡ªåŠ¨ä¿å­˜ï¼‰")
    print("  - metrics.json: è®­ç»ƒæŒ‡æ ‡ï¼ˆSacredè‡ªåŠ¨ä¿å­˜ï¼‰")
    print("\né‡è¦è¯´æ˜:")
    print("  - æ¯ä¸ªepochéƒ½ä¼šä¿å­˜æ¨¡å‹æƒé‡ï¼ˆepoch0.pt ~ epoch{}.ptï¼‰".format(total_epoch-1))
    print("  - è®­ç»ƒæ˜¯è¿ç»­çš„ï¼šæ¯ä¸ªepochåœ¨å‰ä¸€ä¸ªepochçš„åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒ")
    print("  - æœ€åä¸€ä¸ªepochï¼ˆepoch{}.ptï¼‰ä¸ä¸€å®šæ˜¯æœ€ä½³æ¨¡å‹ï¼Œå¯èƒ½å‡ºç°è¿‡æ‹Ÿåˆ".format(total_epoch-1))
    if val_dataloader is not None and best_epoch >= 0:
        print("  - å»ºè®®ä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼ˆbest_model.ptï¼Œå¯¹åº”Epoch {}ï¼‰è¿›è¡Œæµ‹è¯•".format(best_epoch+1))
        print("  - æˆ–æ‰‹åŠ¨æŒ‡å®šepoch: python test.py with train_exp_num={} e={}".format(int(_run._id), best_epoch))
    else:
        print("  - ç”±äºæ²¡æœ‰éªŒè¯é›†ï¼Œé»˜è®¤ä½¿ç”¨æœ€åä¸€ä¸ªepochï¼ˆepoch{}.ptï¼‰".format(total_epoch-1))
    print("\nä¸‹ä¸€æ­¥: è¿è¡Œæµ‹è¯•")
    if val_dataloader is not None and best_epoch >= 0:
        print("  ä½¿ç”¨æœ€ä½³æ¨¡å‹: python test.py with train_exp_num={} e={}".format(int(_run._id), best_epoch))
    print("  ä½¿ç”¨é»˜è®¤ï¼ˆæœ€åä¸€ä¸ªepochï¼‰: python test.py with train_exp_num={}".format(int(_run._id)))
    print("="*60 + "\n")